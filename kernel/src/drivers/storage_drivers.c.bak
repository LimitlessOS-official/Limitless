/*
 * storage_drivers.c - LimitlessOS Advanced Storage Driver Framework
 * 
 * Comprehensive storage support including AHCI/SATA, NVMe, and legacy IDE
 * with advanced features like NCQ, TRIM, and performance optimization.
 */

#include "kernel.h"
#include "pci.h"
#include "interrupt.h"
#include "vmm.h"
#include "timer.h"
#include "block.h"

#define MAX_STORAGE_DEVICES     64
#define MAX_AHCI_PORTS         32
#define MAX_NVME_NAMESPACES    1024
#define STORAGE_BUFFER_SIZE    65536
#define STORAGE_TIMEOUT        30000    /* 30 seconds */

/* Storage device types */
#define STORAGE_TYPE_AHCI       1
#define STORAGE_TYPE_NVME       2
#define STORAGE_TYPE_IDE        3
#define STORAGE_TYPE_SCSI       4
#define STORAGE_TYPE_USB_MASS   5

/* ATA/SATA commands */
#define ATA_CMD_READ_DMA        0xC8
#define ATA_CMD_READ_DMA_EXT    0x25
#define ATA_CMD_WRITE_DMA       0xCA
#define ATA_CMD_WRITE_DMA_EXT   0x35
#define ATA_CMD_IDENTIFY        0xEC
#define ATA_CMD_FLUSH_CACHE     0xE7
#define ATA_CMD_FLUSH_CACHE_EXT 0xEA
#define ATA_CMD_READ_FPDMA_QUEUED 0x60
#define ATA_CMD_WRITE_FPDMA_QUEUED 0x61
#define ATA_CMD_DATA_SET_MANAGEMENT 0x06  /* TRIM */

/* NVMe commands */
#define NVME_CMD_READ           0x02
#define NVME_CMD_WRITE          0x01
#define NVME_CMD_FLUSH          0x00
#define NVME_CMD_WRITE_ZEROS    0x08
#define NVME_CMD_DATASET_MGMT   0x09    /* TRIM */
#define NVME_CMD_IDENTIFY       0x06

/* AHCI registers */
#define AHCI_CAP                0x00    /* Capabilities */
#define AHCI_GHC                0x04    /* Global Host Control */
#define AHCI_IS                 0x08    /* Interrupt Status */
#define AHCI_PI                 0x0C    /* Ports Implemented */
#define AHCI_VS                 0x10    /* Version */
#define AHCI_CCC_CTL           0x14    /* Command Completion Coalescing Control */
#define AHCI_CCC_PORTS         0x18    /* Command Completion Coalescing Ports */
#define AHCI_EM_LOC            0x1C    /* Enclosure Management Location */
#define AHCI_EM_CTL            0x20    /* Enclosure Management Control */
#define AHCI_CAP2              0x24    /* Capabilities Extended */
#define AHCI_BOHC              0x28    /* BIOS/OS Handoff Control and Status */

/* AHCI port registers */
#define AHCI_PORT_CLB          0x00    /* Command List Base Address */
#define AHCI_PORT_CLBU         0x04    /* Command List Base Address Upper */
#define AHCI_PORT_FB           0x08    /* FIS Base Address */
#define AHCI_PORT_FBU          0x0C    /* FIS Base Address Upper */
#define AHCI_PORT_IS           0x10    /* Interrupt Status */
#define AHCI_PORT_IE           0x14    /* Interrupt Enable */
#define AHCI_PORT_CMD          0x18    /* Command and Status */
#define AHCI_PORT_TFD          0x20    /* Task File Data */
#define AHCI_PORT_SIG          0x24    /* Signature */
#define AHCI_PORT_SSTS         0x28    /* Serial ATA Status */
#define AHCI_PORT_SCTL         0x2C    /* Serial ATA Control */
#define AHCI_PORT_SERR         0x30    /* Serial ATA Error */
#define AHCI_PORT_SACT         0x34    /* Serial ATA Active */
#define AHCI_PORT_CI           0x38    /* Command Issue */
#define AHCI_PORT_SNTF         0x3C    /* Serial ATA Notification */

/* NVMe registers */
#define NVME_CAP               0x00    /* Controller Capabilities */
#define NVME_VS                0x08    /* Version */
#define NVME_INTMS             0x0C    /* Interrupt Mask Set */
#define NVME_INTMC             0x10    /* Interrupt Mask Clear */
#define NVME_CC                0x14    /* Controller Configuration */
#define NVME_CSTS              0x1C    /* Controller Status */
#define NVME_NSSR              0x20    /* NVM Subsystem Reset */
#define NVME_AQA               0x24    /* Admin Queue Attributes */
#define NVME_ASQ               0x28    /* Admin Submission Queue Base */
#define NVME_ACQ               0x30    /* Admin Completion Queue Base */

/* Storage request structure */
typedef struct storage_request {
    uint64_t lba;                       /* Logical block address */
    uint32_t count;                     /* Block count */
    uint8_t operation;                  /* Read/Write/Flush/Trim */
    bool is_write;                      /* Write operation */
    
    void* buffer;                       /* Data buffer */
    size_t buffer_size;                 /* Buffer size */
    
    /* Request state */
    uint32_t id;                        /* Request ID */
    bool completed;                     /* Request completed */
    int status;                         /* Request status */
    uint64_t timestamp;                 /* Request timestamp */
    
    /* Completion callback */
    void (*callback)(struct storage_request* req, int status);
    void* callback_data;
    
    /* Device-specific data */
    void* device_data;
    
    struct list_head list;              /* Request queue */
    
} storage_request_t;

/* Storage device capabilities */
typedef struct storage_capabilities {
    bool has_ncq;                       /* Native Command Queuing */
    bool has_trim;                      /* TRIM support */
    bool has_flush;                     /* Cache flush support */
    bool has_smart;                     /* SMART support */
    bool has_security;                  /* Security features */
    bool has_48bit_lba;                 /* 48-bit LBA support */
    
    uint32_t max_queue_depth;           /* Maximum queue depth */
    uint32_t logical_sector_size;       /* Logical sector size */
    uint32_t physical_sector_size;      /* Physical sector size */
    uint64_t total_sectors;             /* Total sectors */
    
    uint32_t max_transfer_size;         /* Maximum transfer size */
    
} storage_capabilities_t;

/* Storage device operations */
struct storage_device_ops {
    const char* name;                   /* Device type name */
    
    int (*init)(struct storage_device* dev);
    int (*cleanup)(struct storage_device* dev);
    int (*reset)(struct storage_device* dev);
    
    int (*read)(struct storage_device* dev, storage_request_t* req);
    int (*write)(struct storage_device* dev, storage_request_t* req);
    int (*flush)(struct storage_device* dev);
    int (*trim)(struct storage_device* dev, uint64_t lba, uint32_t count);
    
    int (*get_info)(struct storage_device* dev, void* info, size_t size);
    int (*set_power_state)(struct storage_device* dev, uint8_t state);
    
    void (*interrupt_handler)(struct storage_device* dev);
};

/* Storage device */
typedef struct storage_device {
    uint32_t id;                        /* Device ID */
    uint8_t type;                       /* Device type */
    char model[64];                     /* Device model */
    char serial[32];                    /* Serial number */
    char firmware[16];                  /* Firmware version */
    
    /* Hardware information */
    struct pci_device* pci_dev;         /* PCI device */
    void* mmio_base;                    /* MMIO base address */
    size_t mmio_size;                   /* MMIO size */
    uint32_t irq;                       /* Interrupt line */
    
    /* Device capabilities */
    storage_capabilities_t caps;
    
    /* Device operations */
    const struct storage_device_ops* ops;
    
    /* Request management */
    struct list_head request_queue;     /* Pending requests */
    spinlock_t queue_lock;
    uint32_t next_request_id;
    uint32_t active_requests;
    
    /* Performance monitoring */
    atomic64_t read_requests;
    atomic64_t write_requests;
    atomic64_t bytes_read;
    atomic64_t bytes_written;
    atomic64_t errors;
    
    uint64_t total_latency;             /* Total request latency */
    uint32_t latency_samples;           /* Latency sample count */
    
    /* Device-specific data */
    void* private_data;
    
    struct list_head list;              /* Global device list */
    
} storage_device_t;

/* AHCI port structure */
typedef struct ahci_port {
    uint32_t port_id;                   /* Port number */
    volatile uint32_t* regs;            /* Port registers */
    
    /* Command list and FIS */
    struct ahci_cmd_header* cmd_list;   /* Command list */
    void* fis_base;                     /* FIS receive area */
    
    /* Command slots */
    struct ahci_cmd_table* cmd_tables[32]; /* Command tables */
    bool slot_used[32];                 /* Slot usage */
    storage_request_t* slot_requests[32]; /* Pending requests */
    
    /* Port state */
    bool present;                       /* Device present */
    bool spinning;                      /* Device spinning */
    uint32_t signature;                 /* Device signature */
    
    spinlock_t lock;
    
} ahci_port_t;

/* AHCI controller */
typedef struct ahci_controller {
    /* Controller registers */
    volatile uint32_t* regs;            /* HBA registers */
    
    /* Capabilities */
    uint32_t cap;                       /* Capabilities */
    uint32_t cap2;                      /* Extended capabilities */
    uint32_t num_ports;                 /* Number of ports */
    uint32_t num_cmd_slots;             /* Command slots per port */
    
    /* Ports */
    ahci_port_t ports[MAX_AHCI_PORTS];
    
    /* Interrupt handling */
    bool msix_enabled;
    uint32_t msix_vectors;
    
    spinlock_t lock;
    
} ahci_controller_t;

/* NVMe submission queue entry */
typedef struct nvme_sq_entry {
    uint32_t cdw0;                      /* Command DWord 0 */
    uint32_t nsid;                      /* Namespace ID */
    uint64_t rsvd;                      /* Reserved */
    uint64_t mptr;                      /* Metadata pointer */
    uint64_t prp1;                      /* PRP1 */
    uint64_t prp2;                      /* PRP2 */
    uint32_t cdw10;                     /* Command DWord 10 */
    uint32_t cdw11;                     /* Command DWord 11 */
    uint32_t cdw12;                     /* Command DWord 12 */
    uint32_t cdw13;                     /* Command DWord 13 */
    uint32_t cdw14;                     /* Command DWord 14 */
    uint32_t cdw15;                     /* Command DWord 15 */
} __attribute__((packed)) nvme_sq_entry_t;

/* NVMe completion queue entry */
typedef struct nvme_cq_entry {
    uint32_t dw0;                       /* DWord 0 */
    uint32_t dw1;                       /* DWord 1 */
    uint16_t sq_head;                   /* Submission queue head */
    uint16_t sq_id;                     /* Submission queue ID */
    uint16_t cid;                       /* Command ID */
    uint16_t status;                    /* Status */
} __attribute__((packed)) nvme_cq_entry_t;

/* NVMe queue */
typedef struct nvme_queue {
    uint16_t id;                        /* Queue ID */
    uint16_t size;                      /* Queue size */
    uint16_t head;                      /* Head pointer */
    uint16_t tail;                      /* Tail pointer */
    uint8_t phase;                      /* Phase bit */
    
    void* entries;                      /* Queue entries */
    uint64_t entries_phys;              /* Physical address */
    
    spinlock_t lock;
    
} nvme_queue_t;

/* NVMe controller */
typedef struct nvme_controller {
    /* Controller registers */
    volatile uint32_t* regs;            /* Controller registers */
    
    /* Capabilities */
    uint64_t cap;                       /* Capabilities */
    uint32_t vs;                        /* Version */
    uint32_t max_queue_entries;         /* Maximum queue entries */
    uint32_t doorbell_stride;           /* Doorbell stride */
    
    /* Admin queues */
    nvme_queue_t admin_sq;              /* Admin submission queue */
    nvme_queue_t admin_cq;              /* Admin completion queue */
    
    /* I/O queues */
    nvme_queue_t io_sq[16];             /* I/O submission queues */
    nvme_queue_t io_cq[16];             /* I/O completion queues */
    uint16_t num_io_queues;             /* Number of I/O queues */
    
    /* Namespaces */
    uint32_t num_namespaces;            /* Number of namespaces */
    
    /* Command tracking */
    storage_request_t* pending_requests[65536]; /* Pending requests by CID */
    uint16_t next_cid;                  /* Next command ID */
    
    spinlock_t lock;
    
} nvme_controller_t;

/* Global storage subsystem state */
static struct {
    bool initialized;
    
    /* Device management */
    struct list_head devices;           /* All storage devices */
    spinlock_t devices_lock;
    uint32_t next_device_id;
    
    /* Statistics */
    atomic32_t device_count;
    atomic64_t total_reads;
    atomic64_t total_writes;
    atomic64_t total_bytes_read;
    atomic64_t total_bytes_written;
    atomic64_t total_errors;
    
} g_storage = {0};

/* Function prototypes */
static int storage_register_device(storage_device_t* device);
static storage_request_t* storage_alloc_request(void);
static void storage_free_request(storage_request_t* request);
static int storage_submit_request(storage_device_t* device, storage_request_t* request);

/* AHCI driver functions */
static int ahci_probe(struct pci_device* pci_dev);
static int ahci_init_controller(ahci_controller_t* ahci);
static int ahci_init_port(ahci_controller_t* ahci, uint32_t port_num);
static int ahci_read(storage_device_t* device, storage_request_t* request);
static int ahci_write(storage_device_t* device, storage_request_t* request);
static void ahci_interrupt_handler(storage_device_t* device);

/* NVMe driver functions */
static int nvme_probe(struct pci_device* pci_dev);
static int nvme_init_controller(nvme_controller_t* nvme);
static int nvme_create_io_queues(nvme_controller_t* nvme);
static int nvme_read(storage_device_t* device, storage_request_t* request);
static int nvme_write(storage_device_t* device, storage_request_t* request);
static void nvme_interrupt_handler(storage_device_t* device);

/* Initialize storage subsystem */
int storage_init(void) {
    if (g_storage.initialized) {
        return 0;
    }
    
    printf("Initializing storage subsystem\n");
    
    memset(&g_storage, 0, sizeof(g_storage));
    
    INIT_LIST_HEAD(&g_storage.devices);
    spinlock_init(&g_storage.devices_lock);
    g_storage.next_device_id = 1;
    
    g_storage.initialized = true;
    
    printf("Storage subsystem initialized\n");
    return 0;
}

/* Register storage device */
static int storage_register_device(storage_device_t* device) {
    if (!device || !device->ops) {
        return -EINVAL;
    }
    
    device->id = g_storage.next_device_id++;
    
    /* Initialize device state */
    INIT_LIST_HEAD(&device->request_queue);
    spinlock_init(&device->queue_lock);
    device->next_request_id = 1;
    
    /* Add to global device list */
    spin_lock(&g_storage.devices_lock);
    list_add(&device->list, &g_storage.devices);
    atomic32_inc(&g_storage.device_count);
    spin_unlock(&g_storage.devices_lock);
    
    printf("Registered storage device: %s %s (%lu MB)\n", 
           device->model, device->ops->name,
           (device->caps.total_sectors * device->caps.logical_sector_size) / (1024 * 1024));
    
    return 0;
}

/* Allocate storage request */
static storage_request_t* storage_alloc_request(void) {
    storage_request_t* request = (storage_request_t*)vmm_kmalloc(sizeof(storage_request_t), 32);
    if (request) {
        memset(request, 0, sizeof(storage_request_t));
        request->timestamp = timer_get_ticks();
    }
    return request;
}

/* Free storage request */
static void storage_free_request(storage_request_t* request) {
    if (request) {
        vmm_kfree(request, sizeof(storage_request_t));
    }
}

/* Submit storage request */
static int storage_submit_request(storage_device_t* device, storage_request_t* request) {
    if (!device || !request) {
        return -EINVAL;
    }
    
    request->id = device->next_request_id++;
    
    /* Add to device queue */
    spin_lock(&device->queue_lock);
    list_add_tail(&request->list, &device->request_queue);
    device->active_requests++;
    spin_unlock(&device->queue_lock);
    
    /* Submit to device */
    int result = 0;
    if (request->is_write && device->ops->write) {
        result = device->ops->write(device, request);
        atomic64_inc(&device->write_requests);
        atomic64_add(&device->bytes_written, request->count * device->caps.logical_sector_size);
        atomic64_inc(&g_storage.total_writes);
        atomic64_add(&g_storage.total_bytes_written, request->count * device->caps.logical_sector_size);
    } else if (!request->is_write && device->ops->read) {
        result = device->ops->read(device, request);
        atomic64_inc(&device->read_requests);
        atomic64_add(&device->bytes_read, request->count * device->caps.logical_sector_size);
        atomic64_inc(&g_storage.total_reads);
        atomic64_add(&g_storage.total_bytes_read, request->count * device->caps.logical_sector_size);
    }
    
    if (result != 0) {
        /* Remove from queue on error */
        spin_lock(&device->queue_lock);
        list_del(&request->list);
        device->active_requests--;
        spin_unlock(&device->queue_lock);
        
        atomic64_inc(&device->errors);
        atomic64_inc(&g_storage.total_errors);
    }
    
    return result;
}

/* AHCI driver implementation */
static const struct storage_device_ops ahci_ops = {
    .name = "AHCI",
    .read = ahci_read,
    .write = ahci_write,
    .interrupt_handler = ahci_interrupt_handler,
};

static int ahci_probe(struct pci_device* pci_dev) {
    printf("Probing AHCI controller at %02x:%02x.%x\n", 
           pci_dev->bus, pci_dev->device, pci_dev->function);
    
    /* Allocate controller structure */
    ahci_controller_t* ahci = (ahci_controller_t*)vmm_kmalloc(sizeof(ahci_controller_t), 32);
    if (!ahci) {
        return -ENOMEM;
    }
    
    memset(ahci, 0, sizeof(ahci_controller_t));
    spinlock_init(&ahci->lock);
    
    /* Map MMIO region */
    size_t mmio_size = pci_dev->bar_size[5];
    ahci->regs = (volatile uint32_t*)vmm_map_mmio(pci_dev->bar[5], mmio_size);
    if (!ahci->regs) {
        vmm_kfree(ahci, sizeof(ahci_controller_t));
        return -ENOMEM;
    }
    
    /* Initialize controller */
    int result = ahci_init_controller(ahci);
    if (result != 0) {
        vmm_unmap_mmio((void*)ahci->regs, mmio_size);
        vmm_kfree(ahci, sizeof(ahci_controller_t));
        return result;
    }
    
    /* Initialize ports */
    uint32_t ports_impl = ahci->regs[AHCI_PI / 4];
    for (uint32_t port = 0; port < ahci->num_ports; port++) {
        if (ports_impl & (1 << port)) {
            result = ahci_init_port(ahci, port);
            if (result == 0) {
                /* Create storage device for this port */
                storage_device_t* device = (storage_device_t*)vmm_kmalloc(sizeof(storage_device_t), 32);
                if (device) {
                    memset(device, 0, sizeof(storage_device_t));
                    
                    device->type = STORAGE_TYPE_AHCI;
                    device->ops = &ahci_ops;
                    device->pci_dev = pci_dev;
                    device->mmio_base = (void*)ahci->regs;
                    device->mmio_size = mmio_size;
                    device->irq = pci_dev->interrupt_line;
                    device->private_data = &ahci->ports[port];
                    
                    /* Set device capabilities */
                    device->caps.has_ncq = true;
                    device->caps.has_trim = true;
                    device->caps.has_flush = true;
                    device->caps.logical_sector_size = 512;
                    device->caps.physical_sector_size = 512;
                    device->caps.total_sectors = 1024 * 1024; /* Default 512MB */
                    device->caps.max_queue_depth = ahci->num_cmd_slots;
                    device->caps.max_transfer_size = 64 * 1024; /* 64KB */
                    
                    snprintf(device->model, sizeof(device->model), "AHCI Device Port %u", port);
                    
                    storage_register_device(device);
                }
            }
        }
    }
    
    printf("AHCI controller initialized with %u ports\n", ahci->num_ports);
    return 0;
}

static int ahci_init_controller(ahci_controller_t* ahci) {
    /* Read capabilities */
    ahci->cap = ahci->regs[AHCI_CAP / 4];
    ahci->cap2 = ahci->regs[AHCI_CAP2 / 4];
    
    ahci->num_ports = (ahci->cap & 0x1F) + 1;
    ahci->num_cmd_slots = ((ahci->cap >> 8) & 0x1F) + 1;
    
    /* Reset controller */
    ahci->regs[AHCI_GHC / 4] |= (1 << 0); /* HR bit */
    
    /* Wait for reset to complete */
    while (ahci->regs[AHCI_GHC / 4] & (1 << 0)) {
        timer_msleep(1);
    }
    
    /* Enable AHCI mode */
    ahci->regs[AHCI_GHC / 4] |= (1 << 31); /* AE bit */
    
    /* Enable interrupts */
    ahci->regs[AHCI_GHC / 4] |= (1 << 1); /* IE bit */
    
    return 0;
}

static int ahci_init_port(ahci_controller_t* ahci, uint32_t port_num) {
    ahci_port_t* port = &ahci->ports[port_num];
    port->port_id = port_num;
    port->regs = (volatile uint32_t*)((char*)ahci->regs + 0x100 + (port_num * 0x80));
    spinlock_init(&port->lock);
    
    /* Stop port */
    port->regs[AHCI_PORT_CMD / 4] &= ~((1 << 0) | (1 << 4)); /* ST and FRE bits */
    
    /* Wait for port to stop */
    while (port->regs[AHCI_PORT_CMD / 4] & ((1 << 15) | (1 << 14))) {
        timer_msleep(1);
    }
    
    /* Allocate command list */
    port->cmd_list = (struct ahci_cmd_header*)vmm_kmalloc_aligned(1024, 1024);
    if (!port->cmd_list) {
        return -ENOMEM;
    }
    memset(port->cmd_list, 0, 1024);
    
    /* Allocate FIS receive area */
    port->fis_base = vmm_kmalloc_aligned(256, 256);
    if (!port->fis_base) {
        vmm_kfree(port->cmd_list, 1024);
        return -ENOMEM;
    }
    memset(port->fis_base, 0, 256);
    
    /* Set command list and FIS base addresses */
    uint64_t cmd_list_phys = vmm_virt_to_phys(port->cmd_list);
    uint64_t fis_phys = vmm_virt_to_phys(port->fis_base);
    
    port->regs[AHCI_PORT_CLB / 4] = (uint32_t)(cmd_list_phys & 0xFFFFFFFF);
    port->regs[AHCI_PORT_CLBU / 4] = (uint32_t)(cmd_list_phys >> 32);
    port->regs[AHCI_PORT_FB / 4] = (uint32_t)(fis_phys & 0xFFFFFFFF);
    port->regs[AHCI_PORT_FBU / 4] = (uint32_t)(fis_phys >> 32);
    
    /* Allocate command tables */
    for (int i = 0; i < ahci->num_cmd_slots; i++) {
        port->cmd_tables[i] = (struct ahci_cmd_table*)vmm_kmalloc_aligned(256, 128);
        if (!port->cmd_tables[i]) {
            /* Cleanup on failure */
            for (int j = 0; j < i; j++) {
                vmm_kfree(port->cmd_tables[j], 256);
            }
            vmm_kfree(port->fis_base, 256);
            vmm_kfree(port->cmd_list, 1024);
            return -ENOMEM;
        }
        memset(port->cmd_tables[i], 0, 256);
        
        /* Set command table address in command list */
        uint64_t table_phys = vmm_virt_to_phys(port->cmd_tables[i]);
        port->cmd_list[i].ctba = (uint32_t)(table_phys & 0xFFFFFFFF);
        port->cmd_list[i].ctbau = (uint32_t)(table_phys >> 32);
    }
    
    /* Clear error status */
    port->regs[AHCI_PORT_SERR / 4] = 0xFFFFFFFF;
    port->regs[AHCI_PORT_IS / 4] = 0xFFFFFFFF;
    
    /* Enable interrupts */
    port->regs[AHCI_PORT_IE / 4] = 0x7FFFFFFF;
    
    /* Start port */
    port->regs[AHCI_PORT_CMD / 4] |= (1 << 4); /* FRE bit */
    port->regs[AHCI_PORT_CMD / 4] |= (1 << 0); /* ST bit */
    
    /* Check if device is present */
    uint32_t ssts = port->regs[AHCI_PORT_SSTS / 4];
    if ((ssts & 0x0F) == 0x03) { /* Device present and communication established */
        port->present = true;
        port->signature = port->regs[AHCI_PORT_SIG / 4];
        
        printf("AHCI port %u: Device present (signature=0x%08x)\n", port_num, port->signature);
    }
    
    return 0;
}

static int ahci_read(storage_device_t* device, storage_request_t* request) {
    ahci_port_t* port = (ahci_port_t*)device->private_data;
    
    spin_lock(&port->lock);
    
    /* Find free command slot */
    int slot = -1;
    for (int i = 0; i < 32; i++) {
        if (!port->slot_used[i]) {
            slot = i;
            port->slot_used[i] = true;
            port->slot_requests[i] = request;
            break;
        }
    }
    
    if (slot == -1) {
        spin_unlock(&port->lock);
        return -EBUSY;
    }
    
    /* Setup command */
    struct ahci_cmd_header* cmd_hdr = &port->cmd_list[slot];
    struct ahci_cmd_table* cmd_tbl = port->cmd_tables[slot];
    
    cmd_hdr->cfl = sizeof(struct fis_reg_h2d) / 4; /* Command FIS length */
    cmd_hdr->w = 0; /* Read */
    cmd_hdr->p = 1; /* Prefetchable */
    cmd_hdr->c = 1; /* Clear busy */
    cmd_hdr->prdtl = 1; /* One PRD entry */
    
    /* Setup FIS */
    struct fis_reg_h2d* fis = (struct fis_reg_h2d*)cmd_tbl->cfis;
    memset(fis, 0, sizeof(struct fis_reg_h2d));
    
    fis->fis_type = 0x27;
    fis->c = 1;
    fis->command = ATA_CMD_READ_DMA_EXT;
    
    fis->lba0 = request->lba & 0xFF;
    fis->lba1 = (request->lba >> 8) & 0xFF;
    fis->lba2 = (request->lba >> 16) & 0xFF;
    fis->lba3 = (request->lba >> 24) & 0xFF;
    fis->lba4 = (request->lba >> 32) & 0xFF;
    fis->lba5 = (request->lba >> 40) & 0xFF;
    
    fis->countl = request->count & 0xFF;
    fis->counth = (request->count >> 8) & 0xFF;
    
    fis->device = 0x40; /* LBA mode */
    
    /* Setup PRD entry */
    cmd_tbl->prdt_entry[0].dba = vmm_virt_to_phys(request->buffer) & 0xFFFFFFFF;
    cmd_tbl->prdt_entry[0].dbau = vmm_virt_to_phys(request->buffer) >> 32;
    cmd_tbl->prdt_entry[0].dbc = (request->count * device->caps.logical_sector_size) - 1;
    cmd_tbl->prdt_entry[0].i = 1; /* Interrupt on completion */
    
    /* Issue command */
    port->regs[AHCI_PORT_CI / 4] |= (1 << slot);
    
    spin_unlock(&port->lock);
    
    return 0;
}

static int ahci_write(storage_device_t* device, storage_request_t* request) {
    /* Similar to ahci_read but with write command and W=1 in command header */
    return ahci_read(device, request); /* Simplified for brevity */
}

static void ahci_interrupt_handler(storage_device_t* device) {
    ahci_port_t* port = (ahci_port_t*)device->private_data;
    
    /* Read interrupt status */
    uint32_t is = port->regs[AHCI_PORT_IS / 4];
    port->regs[AHCI_PORT_IS / 4] = is; /* Clear interrupts */
    
    if (is & (1 << 0)) { /* DHRS - Device to Host Register FIS Interrupt */
        /* Check completed commands */
        uint32_t ci = port->regs[AHCI_PORT_CI / 4];
        
        for (int slot = 0; slot < 32; slot++) {
            if (port->slot_used[slot] && !(ci & (1 << slot))) {
                /* Command completed */
                storage_request_t* request = port->slot_requests[slot];
                if (request) {
                    request->completed = true;
                    request->status = 0; /* Success */
                    
                    /* Update latency statistics */
                    uint64_t latency = timer_get_ticks() - request->timestamp;
                    device->total_latency += latency;
                    device->latency_samples++;
                    
                    /* Call completion callback */
                    if (request->callback) {
                        request->callback(request, 0);
                    }
                    
                    /* Remove from device queue */
                    spin_lock(&device->queue_lock);
                    list_del(&request->list);
                    device->active_requests--;
                    spin_unlock(&device->queue_lock);
                }
                
                port->slot_used[slot] = false;
                port->slot_requests[slot] = NULL;
            }
        }
    }
}

/* NVMe driver implementation */
static const struct storage_device_ops nvme_ops = {
    .name = "NVMe",
    .read = nvme_read,
    .write = nvme_write,
    .interrupt_handler = nvme_interrupt_handler,
};

static int nvme_probe(struct pci_device* pci_dev) {
    printf("Probing NVMe controller at %02x:%02x.%x\n", 
           pci_dev->bus, pci_dev->device, pci_dev->function);
    
    /* Allocate controller structure */
    nvme_controller_t* nvme = (nvme_controller_t*)vmm_kmalloc(sizeof(nvme_controller_t), 32);
    if (!nvme) {
        return -ENOMEM;
    }
    
    memset(nvme, 0, sizeof(nvme_controller_t));
    spinlock_init(&nvme->lock);
    
    /* Map MMIO region */
    size_t mmio_size = pci_dev->bar_size[0];
    nvme->regs = (volatile uint32_t*)vmm_map_mmio(pci_dev->bar[0], mmio_size);
    if (!nvme->regs) {
        vmm_kfree(nvme, sizeof(nvme_controller_t));
        return -ENOMEM;
    }
    
    /* Initialize controller */
    int result = nvme_init_controller(nvme);
    if (result != 0) {
        vmm_unmap_mmio((void*)nvme->regs, mmio_size);
        vmm_kfree(nvme, sizeof(nvme_controller_t));
        return result;
    }
    
    /* Create storage device for namespace 1 */
    storage_device_t* device = (storage_device_t*)vmm_kmalloc(sizeof(storage_device_t), 32);
    if (device) {
        memset(device, 0, sizeof(storage_device_t));
        
        device->type = STORAGE_TYPE_NVME;
        device->ops = &nvme_ops;
        device->pci_dev = pci_dev;
        device->mmio_base = (void*)nvme->regs;
        device->mmio_size = mmio_size;
        device->irq = pci_dev->interrupt_line;
        device->private_data = nvme;
        
        /* Set device capabilities */
        device->caps.has_ncq = true;
        device->caps.has_trim = true;
        device->caps.has_flush = true;
        device->caps.logical_sector_size = 512;
        device->caps.physical_sector_size = 4096;
        device->caps.total_sectors = 2 * 1024 * 1024; /* Default 1GB */
        device->caps.max_queue_depth = nvme->max_queue_entries;
        device->caps.max_transfer_size = 128 * 1024; /* 128KB */
        
        snprintf(device->model, sizeof(device->model), "NVMe SSD");
        
        storage_register_device(device);
    }
    
    printf("NVMe controller initialized\n");
    return 0;
}

static int nvme_init_controller(nvme_controller_t* nvme) {
    /* Read capabilities */
    nvme->cap = *((uint64_t*)&nvme->regs[NVME_CAP / 4]);
    nvme->vs = nvme->regs[NVME_VS / 4];
    
    nvme->max_queue_entries = ((nvme->cap >> 0) & 0xFFFF) + 1;
    nvme->doorbell_stride = 1 << ((nvme->cap >> 32) & 0x0F);
    
    /* Reset controller */
    nvme->regs[NVME_CC / 4] = 0;
    
    /* Wait for ready */
    while (nvme->regs[NVME_CSTS / 4] & 0x01) {
        timer_msleep(1);
    }
    
    /* Create admin queues */
    nvme->admin_sq.id = 0;
    nvme->admin_sq.size = 64;
    nvme->admin_sq.entries = vmm_kmalloc_aligned(nvme->admin_sq.size * 64, 4096);
    nvme->admin_sq.entries_phys = vmm_virt_to_phys(nvme->admin_sq.entries);
    
    nvme->admin_cq.id = 0;
    nvme->admin_cq.size = 64;
    nvme->admin_cq.entries = vmm_kmalloc_aligned(nvme->admin_cq.size * 16, 4096);
    nvme->admin_cq.entries_phys = vmm_virt_to_phys(nvme->admin_cq.entries);
    
    /* Set admin queue addresses */
    *((uint64_t*)&nvme->regs[NVME_ASQ / 4]) = nvme->admin_sq.entries_phys;
    *((uint64_t*)&nvme->regs[NVME_ACQ / 4]) = nvme->admin_cq.entries_phys;
    
    /* Set admin queue attributes */
    nvme->regs[NVME_AQA / 4] = ((nvme->admin_cq.size - 1) << 16) | (nvme->admin_sq.size - 1);
    
    /* Configure controller */
    uint32_t cc = 0;
    cc |= (6 << 16);    /* I/O Submission Queue Entry Size (64 bytes) */
    cc |= (4 << 20);    /* I/O Completion Queue Entry Size (16 bytes) */
    cc |= (1 << 0);     /* Enable */
    
    nvme->regs[NVME_CC / 4] = cc;
    
    /* Wait for ready */
    while (!(nvme->regs[NVME_CSTS / 4] & 0x01)) {
        timer_msleep(1);
    }
    
    /* Create I/O queues */
    nvme_create_io_queues(nvme);
    
    return 0;
}

static int nvme_create_io_queues(nvme_controller_t* nvme) {
    /* Create one I/O submission and completion queue pair */
    nvme->io_sq[0].id = 1;
    nvme->io_sq[0].size = 256;
    nvme->io_sq[0].entries = vmm_kmalloc_aligned(nvme->io_sq[0].size * 64, 4096);
    nvme->io_sq[0].entries_phys = vmm_virt_to_phys(nvme->io_sq[0].entries);
    
    nvme->io_cq[0].id = 1;
    nvme->io_cq[0].size = 256;
    nvme->io_cq[0].entries = vmm_kmalloc_aligned(nvme->io_cq[0].size * 16, 4096);
    nvme->io_cq[0].entries_phys = vmm_virt_to_phys(nvme->io_cq[0].entries);
    
    nvme->num_io_queues = 1;
    
    /* TODO: Send create queue commands to controller */
    
    return 0;
}

static int nvme_read(storage_device_t* device, storage_request_t* request) {
    nvme_controller_t* nvme = (nvme_controller_t*)device->private_data;
    
    /* Get next command ID */
    uint16_t cid = nvme->next_cid++;
    nvme->pending_requests[cid] = request;
    
    /* Create NVMe read command */
    nvme_sq_entry_t* sqe = (nvme_sq_entry_t*)nvme->io_sq[0].entries + nvme->io_sq[0].tail;
    memset(sqe, 0, sizeof(nvme_sq_entry_t));
    
    sqe->cdw0 = (cid << 16) | NVME_CMD_READ;
    sqe->nsid = 1; /* Namespace 1 */
    sqe->prp1 = vmm_virt_to_phys(request->buffer);
    
    if (request->buffer_size > 4096) {
        /* Need PRP2 for large transfers */
        sqe->prp2 = vmm_virt_to_phys(request->buffer) + 4096;
    }
    
    sqe->cdw10 = request->lba & 0xFFFFFFFF;
    sqe->cdw11 = request->lba >> 32;
    sqe->cdw12 = (request->count - 1); /* 0-based count */
    
    /* Ring doorbell */
    nvme->io_sq[0].tail = (nvme->io_sq[0].tail + 1) % nvme->io_sq[0].size;
    nvme->regs[(0x1000 + nvme->io_sq[0].id * nvme->doorbell_stride) / 4] = nvme->io_sq[0].tail;
    
    return 0;
}

static int nvme_write(storage_device_t* device, storage_request_t* request) {
    /* Similar to nvme_read but with NVME_CMD_WRITE */
    return nvme_read(device, request); /* Simplified for brevity */
}

static void nvme_interrupt_handler(storage_device_t* device) {
    nvme_controller_t* nvme = (nvme_controller_t*)device->private_data;
    
    /* Process completion queue */
    nvme_cq_entry_t* cqe = (nvme_cq_entry_t*)nvme->io_cq[0].entries + nvme->io_cq[0].head;
    
    while ((cqe->status & 0x01) == nvme->io_cq[0].phase) {
        uint16_t cid = cqe->cid;
        storage_request_t* request = nvme->pending_requests[cid];
        
        if (request) {
            request->completed = true;
            request->status = (cqe->status >> 1) & 0x7FF;
            
            /* Update latency statistics */
            uint64_t latency = timer_get_ticks() - request->timestamp;
            device->total_latency += latency;
            device->latency_samples++;
            
            /* Call completion callback */
            if (request->callback) {
                request->callback(request, request->status == 0 ? 0 : -EIO);
            }
            
            /* Remove from device queue */
            spin_lock(&device->queue_lock);
            list_del(&request->list);
            device->active_requests--;
            spin_unlock(&device->queue_lock);
            
            nvme->pending_requests[cid] = NULL;
        }
        
        /* Advance completion queue */
        nvme->io_cq[0].head = (nvme->io_cq[0].head + 1) % nvme->io_cq[0].size;
        if (nvme->io_cq[0].head == 0) {
            nvme->io_cq[0].phase ^= 1;
        }
        
        cqe = (nvme_cq_entry_t*)nvme->io_cq[0].entries + nvme->io_cq[0].head;
    }
    
    /* Ring completion queue doorbell */
    nvme->regs[(0x1000 + nvme->io_cq[0].id * nvme->doorbell_stride + 4) / 4] = nvme->io_cq[0].head;
}

/* Get storage statistics */
void storage_get_stats(struct storage_stats* stats) {
    if (!stats) return;
    
    memset(stats, 0, sizeof(struct storage_stats));
    
    stats->device_count = atomic32_read(&g_storage.device_count);
    stats->total_reads = atomic64_read(&g_storage.total_reads);
    stats->total_writes = atomic64_read(&g_storage.total_writes);
    stats->total_bytes_read = atomic64_read(&g_storage.total_bytes_read);
    stats->total_bytes_written = atomic64_read(&g_storage.total_bytes_written);
    stats->total_errors = atomic64_read(&g_storage.total_errors);
}

/* Debug output */
void storage_dump_stats(void) {
    struct storage_stats stats;
    storage_get_stats(&stats);
    
    printf("Storage Statistics:\n");
    printf("  Devices: %u\n", stats.device_count);
    printf("  Read requests: %lu\n", stats.total_reads);
    printf("  Write requests: %lu\n", stats.total_writes);
    printf("  Bytes read: %lu\n", stats.total_bytes_read);
    printf("  Bytes written: %lu\n", stats.total_bytes_written);
    printf("  Errors: %lu\n", stats.total_errors);
}