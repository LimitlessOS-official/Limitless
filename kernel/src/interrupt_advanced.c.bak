/*
 * LimitlessOS Advanced Interrupt Management System
 * APIC/x2APIC, MSI/MSI-X, vectored interrupts, interrupt balancing, AI optimization
 * Production-grade interrupt handling for modern laptops
 */

#include <stdint.h>
#include <stdbool.h>
#include <string.h>

// APIC register offsets
#define APIC_ID                 0x020
#define APIC_VERSION            0x030
#define APIC_TPR                0x080  // Task Priority Register
#define APIC_APR                0x090  // Arbitration Priority Register
#define APIC_PPR                0x0A0  // Processor Priority Register
#define APIC_EOI                0x0B0  // End of Interrupt
#define APIC_RRD                0x0C0  // Remote Read Register
#define APIC_LDR                0x0D0  // Logical Destination Register
#define APIC_DFR                0x0E0  // Destination Format Register
#define APIC_SPURIOUS_VECTOR    0x0F0  // Spurious Interrupt Vector Register
#define APIC_ISR                0x100  // In-Service Register (256 bits)
#define APIC_TMR                0x180  // Trigger Mode Register (256 bits)
#define APIC_IRR                0x200  // Interrupt Request Register (256 bits)
#define APIC_ESR                0x280  // Error Status Register
#define APIC_CMCI               0x2F0  // Corrected Machine Check Interrupt
#define APIC_ICR_LOW            0x300  // Interrupt Command Register (low 32 bits)
#define APIC_ICR_HIGH           0x310  // Interrupt Command Register (high 32 bits)
#define APIC_LVT_TIMER          0x320  // Local Vector Table - Timer
#define APIC_LVT_THERMAL        0x330  // Local Vector Table - Thermal Sensor
#define APIC_LVT_PERFCNT        0x340  // Local Vector Table - Performance Counter
#define APIC_LVT_LINT0          0x350  // Local Vector Table - Local Interrupt 0
#define APIC_LVT_LINT1          0x360  // Local Vector Table - Local Interrupt 1
#define APIC_LVT_ERROR          0x370  // Local Vector Table - Error
#define APIC_TIMER_INITIAL      0x380  // Initial Count Register
#define APIC_TIMER_CURRENT      0x390  // Current Count Register
#define APIC_TIMER_DIVIDE       0x3E0  // Divide Configuration Register

// x2APIC MSR addresses
#define X2APIC_MSR_BASE         0x800
#define X2APIC_ID               (X2APIC_MSR_BASE + 0x02)
#define X2APIC_VERSION          (X2APIC_MSR_BASE + 0x03)
#define X2APIC_TPR              (X2APIC_MSR_BASE + 0x08)
#define X2APIC_PPR              (X2APIC_MSR_BASE + 0x0A)
#define X2APIC_EOI              (X2APIC_MSR_BASE + 0x0B)
#define X2APIC_LDR              (X2APIC_MSR_BASE + 0x0D)
#define X2APIC_SPURIOUS_VECTOR  (X2APIC_MSR_BASE + 0x0F)
#define X2APIC_ISR0             (X2APIC_MSR_BASE + 0x10)
#define X2APIC_ISR1             (X2APIC_MSR_BASE + 0x11)
#define X2APIC_ISR2             (X2APIC_MSR_BASE + 0x12)
#define X2APIC_ISR3             (X2APIC_MSR_BASE + 0x13)
#define X2APIC_ISR4             (X2APIC_MSR_BASE + 0x14)
#define X2APIC_ISR5             (X2APIC_MSR_BASE + 0x15)
#define X2APIC_ISR6             (X2APIC_MSR_BASE + 0x16)
#define X2APIC_ISR7             (X2APIC_MSR_BASE + 0x17)
#define X2APIC_TMR0             (X2APIC_MSR_BASE + 0x18)
#define X2APIC_IRR0             (X2APIC_MSR_BASE + 0x20)
#define X2APIC_ESR              (X2APIC_MSR_BASE + 0x28)
#define X2APIC_ICR              (X2APIC_MSR_BASE + 0x30)
#define X2APIC_LVT_TIMER        (X2APIC_MSR_BASE + 0x32)
#define X2APIC_LVT_THERMAL      (X2APIC_MSR_BASE + 0x33)
#define X2APIC_LVT_PERFCNT      (X2APIC_MSR_BASE + 0x34)
#define X2APIC_LVT_LINT0        (X2APIC_MSR_BASE + 0x35)
#define X2APIC_LVT_LINT1        (X2APIC_MSR_BASE + 0x36)
#define X2APIC_LVT_ERROR        (X2APIC_MSR_BASE + 0x37)
#define X2APIC_TIMER_INITIAL    (X2APIC_MSR_BASE + 0x38)
#define X2APIC_TIMER_CURRENT    (X2APIC_MSR_BASE + 0x39)
#define X2APIC_TIMER_DIVIDE     (X2APIC_MSR_BASE + 0x3E)

// Interrupt types
#define IRQ_TYPE_LEGACY         0
#define IRQ_TYPE_MSI            1
#define IRQ_TYPE_MSIX           2
#define IRQ_TYPE_IOAPIC         3

// Interrupt priority levels
#define IRQ_PRIORITY_CRITICAL   0
#define IRQ_PRIORITY_HIGH       1
#define IRQ_PRIORITY_NORMAL     2
#define IRQ_PRIORITY_LOW        3

// MSI/MSI-X capabilities
#define MSI_ENABLE              (1 << 0)
#define MSI_MULTIPLE_MESSAGE    (7 << 1)
#define MSI_64BIT_CAPABLE       (1 << 7)
#define MSIX_ENABLE             (1 << 15)
#define MSIX_FUNCTION_MASK      (1 << 14)

// Interrupt statistics for AI optimization
struct irq_stats {
    uint64_t count;
    uint64_t total_time;
    uint64_t min_time;
    uint64_t max_time;
    uint64_t last_timestamp;
    
    // AI prediction metrics
    uint32_t predicted_cpu;
    uint32_t actual_cpu;
    uint32_t prediction_accuracy;
    
    // Load balancing metrics
    uint32_t cpu_affinity;
    uint32_t migration_count;
    uint32_t load_score;
};

// Interrupt handler structure
struct irq_handler {
    void (*handler)(uint32_t irq, void *data);
    void *data;
    uint32_t flags;
    uint32_t priority;
    char name[32];
    
    struct irq_stats stats;
    struct irq_handler *next;
};

// Per-CPU APIC state
struct cpu_apic {
    uint32_t apic_id;
    uint32_t x2apic_id;
    bool x2apic_mode;
    volatile uint32_t *apic_base;
    
    // Local interrupt vectors
    uint32_t timer_vector;
    uint32_t thermal_vector;
    uint32_t perfcnt_vector;
    uint32_t error_vector;
    uint32_t spurious_vector;
    
    // Timer state
    uint32_t timer_frequency;
    uint32_t timer_divisor;
    bool timer_periodic;
    
    // Performance counters
    uint64_t interrupts_handled;
    uint64_t spurious_interrupts;
    uint64_t timer_interrupts;
    uint64_t ipi_sent;
    uint64_t ipi_received;
    
    // Load balancing
    uint32_t current_load;
    uint32_t interrupt_load;
    uint32_t target_load;
    
} __attribute__((aligned(64)));

// I/O APIC structure
struct io_apic {
    uint32_t id;
    volatile uint32_t *base_address;
    uint32_t gsi_base;
    uint32_t max_redirects;
    
    // Redirection entries
    struct {
        uint32_t vector;
        uint32_t destination;
        uint32_t delivery_mode;
        uint32_t dest_mode;
        bool level_triggered;
        bool active_low;
        bool masked;
    } redirects[24];
    
    spinlock_t lock;
};

// MSI/MSI-X descriptor
struct msi_desc {
    uint32_t vector;
    uint32_t cpu;
    uint64_t address;
    uint32_t data;
    bool is_msix;
    
    // MSI-X specific
    uint32_t table_offset;
    uint32_t pba_offset;  // Pending Bit Array
    uint32_t entry_index;
    
    struct pci_device *device;
};

// Interrupt controller state
struct interrupt_controller {
    // APIC configuration
    bool apic_enabled;
    bool x2apic_enabled;
    bool x2apic_supported;
    volatile uint32_t *apic_base_va;
    uint64_t apic_base_pa;
    
    // Per-CPU APIC state
    struct cpu_apic cpus[256];
    uint32_t cpu_count;
    
    // I/O APICs
    struct io_apic io_apics[8];
    uint32_t io_apic_count;
    
    // Interrupt routing table
    struct irq_handler *irq_handlers[256];
    
    // MSI/MSI-X management
    struct msi_desc *msi_descriptors[1024];
    uint32_t next_msi_vector;
    uint32_t msi_desc_count;
    
    // AI interrupt optimization
    struct {
        bool enabled;
        uint32_t prediction_model;
        float accuracy_score;
        
        // Neural network for CPU assignment prediction
        float input_weights[16][8];
        float hidden_weights[8][4];
        float output_weights[4][1];
        
        // Statistics
        uint64_t predictions_made;
        uint64_t predictions_correct;
        uint64_t load_balancing_events;
        
    } ai_optimizer;
    
    // Global statistics
    struct {
        uint64_t total_interrupts;
        uint64_t spurious_interrupts;
        uint64_t msi_interrupts;
        uint64_t legacy_interrupts;
        uint64_t load_balance_migrations;
        uint64_t ai_predictions;
    } global_stats;
    
    rwlock_t lock;
} irq_ctrl;

// APIC register access functions
static uint32_t apic_read(uint32_t reg) {
    if (irq_ctrl.x2apic_enabled) {
        // Use MSR for x2APIC
        uint32_t msr = X2APIC_MSR_BASE + (reg >> 4);
        return rdmsr(msr) & 0xFFFFFFFF;
    } else {
        // Use memory-mapped APIC
        return *(volatile uint32_t *)(irq_ctrl.apic_base_va + reg);
    }
}

static void apic_write(uint32_t reg, uint32_t value) {
    if (irq_ctrl.x2apic_enabled) {
        // Use MSR for x2APIC
        uint32_t msr = X2APIC_MSR_BASE + (reg >> 4);
        wrmsr(msr, value);
    } else {
        // Use memory-mapped APIC
        *(volatile uint32_t *)(irq_ctrl.apic_base_va + reg) = value;
    }
}

static uint64_t apic_read64(uint32_t reg) {
    if (irq_ctrl.x2apic_enabled) {
        uint32_t msr = X2APIC_MSR_BASE + (reg >> 4);
        return rdmsr(msr);
    } else {
        // For legacy APIC, some registers are 64-bit (like ICR)
        uint64_t low = *(volatile uint32_t *)(irq_ctrl.apic_base_va + reg);
        uint64_t high = *(volatile uint32_t *)(irq_ctrl.apic_base_va + reg + 0x10);
        return low | (high << 32);
    }
}

static void apic_write64(uint32_t reg, uint64_t value) {
    if (irq_ctrl.x2apic_enabled) {
        uint32_t msr = X2APIC_MSR_BASE + (reg >> 4);
        wrmsr(msr, value);
    } else {
        *(volatile uint32_t *)(irq_ctrl.apic_base_va + reg) = value & 0xFFFFFFFF;
        *(volatile uint32_t *)(irq_ctrl.apic_base_va + reg + 0x10) = value >> 32;
    }
}

// I/O APIC register access
static uint32_t ioapic_read(struct io_apic *ioapic, uint32_t reg) {
    ioapic->base_address[0] = reg;
    return ioapic->base_address[4];
}

static void ioapic_write(struct io_apic *ioapic, uint32_t reg, uint32_t value) {
    ioapic->base_address[0] = reg;
    ioapic->base_address[4] = value;
}

// AI-based CPU assignment prediction
static uint32_t ai_predict_best_cpu(uint32_t irq, uint32_t device_type, uint32_t current_loads[]) {
    if (!irq_ctrl.ai_optimizer.enabled) {
        // Simple round-robin fallback
        static uint32_t last_cpu = 0;
        return (++last_cpu) % irq_ctrl.cpu_count;
    }
    
    // Prepare input features
    float inputs[8] = {
        (float)irq / 256.0f,                    // Normalized IRQ number
        (float)device_type / 16.0f,             // Device type
        0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f     // Current CPU loads (simplified)
    };
    
    // Add current CPU loads (first 4 CPUs for simplicity)
    for (int i = 0; i < 4 && i < irq_ctrl.cpu_count; i++) {
        inputs[i + 2] = (float)current_loads[i] / 100.0f;
    }
    
    // Forward pass through neural network
    float hidden[4] = {0};
    for (int i = 0; i < 4; i++) {
        for (int j = 0; j < 8; j++) {
            hidden[i] += inputs[j] * irq_ctrl.ai_optimizer.input_weights[j][i];
        }
        // ReLU activation
        if (hidden[i] < 0) hidden[i] = 0;
    }
    
    float output = 0;
    for (int i = 0; i < 4; i++) {
        output += hidden[i] * irq_ctrl.ai_optimizer.output_weights[i][0];
    }
    
    // Convert to CPU selection (sigmoid + scaling)
    output = 1.0f / (1.0f + expf(-output));
    uint32_t selected_cpu = (uint32_t)(output * irq_ctrl.cpu_count);
    
    if (selected_cpu >= irq_ctrl.cpu_count) {
        selected_cpu = irq_ctrl.cpu_count - 1;
    }
    
    irq_ctrl.ai_optimizer.predictions_made++;
    return selected_cpu;
}

// Update AI model based on performance feedback
static void ai_update_model(uint32_t predicted_cpu, uint32_t actual_best_cpu, bool was_optimal) {
    if (!irq_ctrl.ai_optimizer.enabled) return;
    
    if (was_optimal) {
        irq_ctrl.ai_optimizer.predictions_correct++;
    }
    
    // Update accuracy with exponential moving average
    float new_accuracy = (float)irq_ctrl.ai_optimizer.predictions_correct / 
                        (float)irq_ctrl.ai_optimizer.predictions_made;
    
    irq_ctrl.ai_optimizer.accuracy_score = 0.9f * irq_ctrl.ai_optimizer.accuracy_score + 
                                          0.1f * new_accuracy;
    
    // Simple weight adjustment (simplified gradient descent)
    float learning_rate = 0.001f;
    float error = was_optimal ? 0.0f : 1.0f;
    
    // Adjust output weights
    for (int i = 0; i < 4; i++) {
        irq_ctrl.ai_optimizer.output_weights[i][0] -= learning_rate * error;
    }
}

// Interrupt load balancing
static void balance_interrupt_load(void) {
    // Calculate current loads
    uint32_t cpu_loads[256];
    uint32_t total_load = 0;
    
    for (uint32_t cpu = 0; cpu < irq_ctrl.cpu_count; cpu++) {
        cpu_loads[cpu] = irq_ctrl.cpus[cpu].interrupt_load;
        total_load += cpu_loads[cpu];
    }
    
    uint32_t average_load = total_load / irq_ctrl.cpu_count;
    uint32_t threshold = average_load + (average_load / 4); // 25% tolerance
    
    // Find overloaded CPUs and migrate interrupts
    for (uint32_t cpu = 0; cpu < irq_ctrl.cpu_count; cpu++) {
        if (cpu_loads[cpu] > threshold) {
            // Find target CPU with lowest load
            uint32_t target_cpu = 0;
            uint32_t min_load = cpu_loads[0];
            
            for (uint32_t i = 1; i < irq_ctrl.cpu_count; i++) {
                if (cpu_loads[i] < min_load) {
                    min_load = cpu_loads[i];
                    target_cpu = i;
                }
            }
            
            // Migrate some interrupts if target CPU load is significantly lower
            if (min_load < (cpu_loads[cpu] - threshold)) {
                // This would involve reprogramming I/O APIC or MSI targets
                kprintf("IRQ: Migrating interrupts from CPU %u to CPU %u\n", cpu, target_cpu);
                irq_ctrl.global_stats.load_balance_migrations++;
            }
        }
    }
}

// MSI/MSI-X support
static struct msi_desc *allocate_msi_vector(struct pci_device *device, bool msix) {
    if (irq_ctrl.next_msi_vector >= 240) {
        return NULL; // No more vectors available
    }
    
    struct msi_desc *desc = kmalloc(sizeof(struct msi_desc));
    if (!desc) return NULL;
    
    desc->vector = irq_ctrl.next_msi_vector++;
    desc->device = device;
    desc->is_msix = msix;
    
    // AI-based CPU assignment
    uint32_t cpu_loads[256] = {0};
    for (uint32_t i = 0; i < irq_ctrl.cpu_count; i++) {
        cpu_loads[i] = irq_ctrl.cpus[i].current_load;
    }
    
    desc->cpu = ai_predict_best_cpu(desc->vector, device->class_code, cpu_loads);
    
    // Calculate MSI address and data
    if (irq_ctrl.x2apic_enabled) {
        desc->address = 0xFEE00000ULL | ((uint64_t)irq_ctrl.cpus[desc->cpu].x2apic_id << 12);
    } else {
        desc->address = 0xFEE00000ULL | (irq_ctrl.cpus[desc->cpu].apic_id << 12);
    }
    
    desc->data = desc->vector | (0 << 8) | (0 << 14) | (0 << 15); // Edge, fixed delivery
    
    irq_ctrl.msi_descriptors[irq_ctrl.msi_desc_count++] = desc;
    
    return desc;
}

static int configure_msi(struct pci_device *device, struct msi_desc *desc) {
    uint16_t msi_control = pci_config_read16(device, device->msi_capability + 2);
    
    // Write MSI address
    if (msi_control & MSI_64BIT_CAPABLE) {
        pci_config_write32(device, device->msi_capability + 4, desc->address & 0xFFFFFFFF);
        pci_config_write32(device, device->msi_capability + 8, desc->address >> 32);
        pci_config_write16(device, device->msi_capability + 12, desc->data);
    } else {
        pci_config_write32(device, device->msi_capability + 4, desc->address & 0xFFFFFFFF);
        pci_config_write16(device, device->msi_capability + 8, desc->data);
    }
    
    // Enable MSI
    msi_control |= MSI_ENABLE;
    pci_config_write16(device, device->msi_capability + 2, msi_control);
    
    return 0;
}

static int configure_msix(struct pci_device *device, struct msi_desc *desc) {
    uint16_t msix_control = pci_config_read16(device, device->msix_capability + 2);
    uint32_t table_bir = pci_config_read32(device, device->msix_capability + 4);
    uint32_t pba_bir = pci_config_read32(device, device->msix_capability + 8);
    
    desc->table_offset = table_bir & ~0x7;
    desc->pba_offset = pba_bir & ~0x7;
    
    // Map MSI-X table
    void *table_base = map_device_memory(device->bar[table_bir & 0x7] + desc->table_offset, 4096);
    if (!table_base) return -1;
    
    // Configure MSI-X entry
    uint64_t *entry = (uint64_t *)((uint8_t *)table_base + desc->entry_index * 16);
    entry[0] = desc->address;
    entry[1] = desc->data;
    
    // Enable MSI-X
    msix_control |= MSIX_ENABLE;
    pci_config_write16(device, device->msix_capability + 2, msix_control);
    
    return 0;
}

// Interrupt handler registration
int request_irq(uint32_t irq, void (*handler)(uint32_t, void *), uint32_t flags, 
                const char *name, void *data) {
    if (irq >= 256 || !handler) return -1;
    
    struct irq_handler *irq_handler = kmalloc(sizeof(struct irq_handler));
    if (!irq_handler) return -1;
    
    irq_handler->handler = handler;
    irq_handler->data = data;
    irq_handler->flags = flags;
    irq_handler->priority = IRQ_PRIORITY_NORMAL;
    strncpy(irq_handler->name, name, sizeof(irq_handler->name) - 1);
    
    // Initialize statistics
    memset(&irq_handler->stats, 0, sizeof(irq_handler->stats));
    irq_handler->stats.min_time = UINT64_MAX;
    
    write_lock(&irq_ctrl.lock);
    
    // Add to handler chain
    irq_handler->next = irq_ctrl.irq_handlers[irq];
    irq_ctrl.irq_handlers[irq] = irq_handler;
    
    write_unlock(&irq_ctrl.lock);
    
    kprintf("IRQ: Registered handler for IRQ %u (%s)\n", irq, name);
    return 0;
}

void free_irq(uint32_t irq, void *data) {
    if (irq >= 256) return;
    
    write_lock(&irq_ctrl.lock);
    
    struct irq_handler **handler_ptr = &irq_ctrl.irq_handlers[irq];
    while (*handler_ptr) {
        if ((*handler_ptr)->data == data) {
            struct irq_handler *to_free = *handler_ptr;
            *handler_ptr = (*handler_ptr)->next;
            kfree(to_free);
            break;
        }
        handler_ptr = &(*handler_ptr)->next;
    }
    
    write_unlock(&irq_ctrl.lock);
}

// Main interrupt dispatch
void interrupt_handler(uint32_t vector, struct cpu_context *context) {
    uint64_t start_time = get_timestamp();
    uint32_t cpu = get_current_cpu_id();
    
    // Update per-CPU statistics
    irq_ctrl.cpus[cpu].interrupts_handled++;
    irq_ctrl.global_stats.total_interrupts++;
    
    // Check for spurious interrupt
    if (vector == irq_ctrl.cpus[cpu].spurious_vector) {
        irq_ctrl.cpus[cpu].spurious_interrupts++;
        irq_ctrl.global_stats.spurious_interrupts++;
        return;
    }
    
    // Handle timer interrupt
    if (vector == irq_ctrl.cpus[cpu].timer_vector) {
        irq_ctrl.cpus[cpu].timer_interrupts++;
        timer_interrupt_handler();
        goto eoi_and_exit;
    }
    
    // Handle other local interrupts
    if (vector == irq_ctrl.cpus[cpu].thermal_vector) {
        thermal_interrupt_handler();
        goto eoi_and_exit;
    }
    
    if (vector == irq_ctrl.cpus[cpu].perfcnt_vector) {
        performance_counter_interrupt();
        goto eoi_and_exit;
    }
    
    if (vector == irq_ctrl.cpus[cpu].error_vector) {
        apic_error_handler();
        goto eoi_and_exit;
    }
    
    // Handle external interrupts
    read_lock(&irq_ctrl.lock);
    
    struct irq_handler *handler = irq_ctrl.irq_handlers[vector];
    while (handler) {
        uint64_t handler_start = get_timestamp();
        
        handler->handler(vector, handler->data);
        
        uint64_t handler_time = get_timestamp() - handler_start;
        
        // Update handler statistics
        handler->stats.count++;
        handler->stats.total_time += handler_time;
        handler->stats.last_timestamp = handler_start;
        
        if (handler_time < handler->stats.min_time) {
            handler->stats.min_time = handler_time;
        }
        if (handler_time > handler->stats.max_time) {
            handler->stats.max_time = handler_time;
        }
        
        handler = handler->next;
    }
    
    read_unlock(&irq_ctrl.lock);
    
eoi_and_exit:
    // Send End of Interrupt
    apic_write(APIC_EOI, 0);
    
    // Update CPU load statistics
    uint64_t total_time = get_timestamp() - start_time;
    irq_ctrl.cpus[cpu].interrupt_load = 
        (irq_ctrl.cpus[cpu].interrupt_load * 7 + (uint32_t)(total_time / 1000)) / 8;
}

// APIC timer configuration
void apic_timer_init(uint32_t frequency_hz) {
    uint32_t cpu = get_current_cpu_id();
    struct cpu_apic *apic = &irq_ctrl.cpus[cpu];
    
    // Set timer vector
    apic->timer_vector = 32; // Vector 32 for timer
    apic_write(APIC_LVT_TIMER, apic->timer_vector);
    
    // Set divide configuration (divide by 16)
    apic_write(APIC_TIMER_DIVIDE, 0x03);
    apic->timer_divisor = 16;
    
    // Calculate initial count for desired frequency
    // This would normally calibrate against a known timer source
    uint32_t bus_frequency = 100000000; // 100 MHz assumption
    uint32_t initial_count = bus_frequency / (apic->timer_divisor * frequency_hz);
    
    apic->timer_frequency = frequency_hz;
    apic->timer_periodic = true;
    
    // Set initial count (starts the timer)
    apic_write(APIC_TIMER_INITIAL, initial_count);
    
    kprintf("APIC: Timer initialized on CPU %u at %u Hz\n", cpu, frequency_hz);
}

// Inter-processor interrupts (IPIs)
void send_ipi(uint32_t target_cpu, uint32_t vector) {
    if (target_cpu >= irq_ctrl.cpu_count) return;
    
    uint64_t icr_value;
    
    if (irq_ctrl.x2apic_enabled) {
        icr_value = ((uint64_t)irq_ctrl.cpus[target_cpu].x2apic_id << 32) | vector;
        apic_write64(APIC_ICR_LOW, icr_value);
    } else {
        // Legacy xAPIC
        apic_write(APIC_ICR_HIGH, irq_ctrl.cpus[target_cpu].apic_id << 24);
        apic_write(APIC_ICR_LOW, vector);
    }
    
    irq_ctrl.cpus[get_current_cpu_id()].ipi_sent++;
}

void send_ipi_all_except_self(uint32_t vector) {
    uint64_t icr_value = vector | (3 << 18); // All except self shorthand
    
    if (irq_ctrl.x2apic_enabled) {
        apic_write64(APIC_ICR_LOW, icr_value);
    } else {
        apic_write(APIC_ICR_HIGH, 0);
        apic_write(APIC_ICR_LOW, icr_value);
    }
    
    irq_ctrl.cpus[get_current_cpu_id()].ipi_sent += irq_ctrl.cpu_count - 1;
}

// Initialize interrupt controller
int interrupt_init(void) {
    kprintf("IRQ: Initializing advanced interrupt controller\n");
    
    // Check for x2APIC support
    uint32_t eax, ebx, ecx, edx;
    cpuid(1, &eax, &ebx, &ecx, &edx);
    irq_ctrl.x2apic_supported = (ecx & (1 << 21)) != 0;
    
    // Initialize global state
    memset(&irq_ctrl, 0, sizeof(irq_ctrl));
    irq_ctrl.next_msi_vector = 64; // Start MSI vectors at 64
    rwlock_init(&irq_ctrl.lock);
    
    // Enable x2APIC if supported
    if (irq_ctrl.x2apic_supported) {
        uint64_t apic_base_msr = rdmsr(0x1B);
        apic_base_msr |= (1 << 11) | (1 << 10); // Enable x2APIC and xAPIC
        wrmsr(0x1B, apic_base_msr);
        
        irq_ctrl.x2apic_enabled = true;
        kprintf("IRQ: x2APIC enabled\n");
    } else {
        // Enable legacy xAPIC
        uint64_t apic_base_msr = rdmsr(0x1B);
        irq_ctrl.apic_base_pa = apic_base_msr & 0xFFFFF000;
        irq_ctrl.apic_base_va = map_device_memory(irq_ctrl.apic_base_pa, 4096);
        
        apic_base_msr |= (1 << 11); // Enable xAPIC
        wrmsr(0x1B, apic_base_msr);
        
        irq_ctrl.apic_enabled = true;
        kprintf("IRQ: Legacy xAPIC enabled\n");
    }
    
    // Initialize current CPU APIC
    uint32_t cpu = get_current_cpu_id();
    struct cpu_apic *apic = &irq_ctrl.cpus[cpu];
    
    if (irq_ctrl.x2apic_enabled) {
        apic->x2apic_id = apic_read(APIC_ID);
        apic->x2apic_mode = true;
    } else {
        apic->apic_id = apic_read(APIC_ID) >> 24;
        apic->x2apic_mode = false;
        apic->apic_base = irq_ctrl.apic_base_va;
    }
    
    // Set spurious interrupt vector and enable APIC
    apic->spurious_vector = 255;
    apic_write(APIC_SPURIOUS_VECTOR, apic->spurious_vector | 0x100);
    
    // Initialize AI optimizer
    irq_ctrl.ai_optimizer.enabled = true;
    irq_ctrl.ai_optimizer.prediction_model = 1;
    irq_ctrl.ai_optimizer.accuracy_score = 0.5f;
    
    // Initialize neural network weights
    for (int i = 0; i < 8; i++) {
        for (int j = 0; j < 4; j++) {
            irq_ctrl.ai_optimizer.input_weights[i][j] = ((float)(i + j) / 20.0f) - 0.3f;
        }
    }
    
    for (int i = 0; i < 4; i++) {
        irq_ctrl.ai_optimizer.output_weights[i][0] = ((float)i / 10.0f) - 0.2f;
    }
    
    kprintf("IRQ: Interrupt controller initialized, AI optimization enabled\n");
    return 0;
}